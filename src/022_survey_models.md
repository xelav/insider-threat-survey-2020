
### Методы классификации инсайдерского поведения

В работе [@rashidNewTakeDetecting2016] используется скрытая марковская
модель (Hidden Markov Model - **HMM**). Скрытая марковская модель
представляет собой обычную марковскую модель, в которой модель выводит
некоторый символ каждый раз перед переходом в следующее состояние.
Модель называется скрытой, поскольку мы наблюдаем только выходы модели,
а последовательность переходов состояний скрыта от нас.\

В данной работе все действия пользователей кодируются числами. Затем
действия собираются отдельно для каждого пользователя и сортируются по
времени. На первых пяти неделях модель обучается (используется
предположение, что за это время инсайдерского поведения не было), для
последующих недель модель предсказывает вероятность аномальности
поведения и только потом обучается. Поведение за неделю считается
аномальным, если оно превышает заданный порог.\

Эксперименты на CERT 4.2 после подбора гиперпараметров показали AUC ROC
$0.83$.\

В [@noeverClassifierSuitesInsider2019] было испробовано множество
различных семейств алгоритмов машинного обучения. В этой статье
приводится к заключению, что алгоритмы случайного леса и бустинга
показывают наилучшие результаты. Важно отметить, что они в качестве
признаков также использовали сентимент-анализ текста электронной почты и
содержания посещенных сайтов.\

В работе [@yuanAttentionBasedLSTMInsider2019] предложен способ класификации инсайдерского поведения на основе нейронной сети с LSTM для извлечения последовательной информации и Attention-слоем для классификации. Attention позволяет нейронной сети самостоятельно перевзвесить элементы последовательности, выделяя таким образом наиболее важные элементы.  Вычисления в Attention-слое следующие:

$$
\mathbf{u_t} =  \tanh (\mathbf{W_a}\mathbf{h_t}+\mathbf{b_a})
$$
$$
\alpha_t =  \frac{\exp (score(\mathbf{u_t},\mathbf{u_a}))}{\sum_i score(\exp (\mathbf{u_i},\mathbf{u_a}}))
$$
$$
\mathbf{v} =  \sum_t \alpha_t\mathbf{h_t}
$$
где $\mathbf{W_a}$ - обучаемая матрица параметров, $\mathbf{u_a}$ - обучаемый вектор контекста, $\mathbf{h_t}$ t-ый выход из LSTM-слоя, $score(\mathbf{a}, \mathbf{b})$ - функция, измеряющая схожесть векторов. Чаще всего берется скалярное произведение векторов:
$$score(\mathbf(a), \mathbf(b)) = \mathbf{a}^T\mathbf{b}$$
Полученный вектор $v$ подается на вход Softmax классификатору:
$$
p(\hat{y}=k | \mathbf{v}) = \frac{\exp(\mathbf{W_k^T}\mathbf{v} + \mathbf{b_k})}{\sum^K_{i=1} \exp(\mathbf{W_i^T}\mathbf{v} + \mathbf{b_i})}
$$
где, $\hat{y}$ - предсказанный класс, $K$ - количество классов, $\mathbf{W_k}$ и $\mathbf{b_k}$ - обучаемые параметры для k-ого класса.

В [@yuanAttentionBasedLSTMInsider2019], при сравнении с базовой моделью без Attention-слоя, усложненная модель показала лучший результат на наборе данных CERT. Это указывает на то, что Attention-слой имеет потенциал для использовании и в задаче обнаружении инсайдеров.