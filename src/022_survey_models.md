
### Методы классификации инсайдерского поведения

В работе [@rashidNewTakeDetecting2016] используется скрытая марковская
модель (Hidden Markov Model - **HMM**). Скрытая марковская модель
представляет собой обычную марковскую модель, в которой модель выводит
некоторый символ каждый раз перед переходом в следующее состояние.
Модель называется скрытой, поскольку мы наблюдаем только выходы модели,
а последовательность переходов состояний скрыта от нас.\
В данной работе все действия пользователей кодируются числами. Затем
действия собираются отдельно для каждого пользователя и сортируются по
времени. На первых пяти неделях модель обучается (используется
предположение, что за это время инсайдерского поведения не было), для
последующих недель модель предсказывает вероятность аномальности
поведения и только потом обучается. Поведение за неделю считается
аномальным, если оно превышает заданный порог.\

Эксперименты на CERT 4.2 после подбора гиперпараметров показали AUC ROC
$0.83$.\

В [@noeverClassifierSuitesInsider2019] было испробовано множество
различных семейств алгоритмов машинного обучения. В этой статье
приводится к заключению, что алгоритмы случайного леса и бустинга
показывают наилучшие результаты. Важно отметить, что они в качестве
признаков также использовали сентимент-анализ текста электронной почты и
содержания посещенных сайтов.\

Работа [@yuanInsiderThreatDetection2018b] использует CNN-классификатор и
для классификации инсайдерского поведения. Классификатор принимает на вход
Скрытое состояние последнего слоя LSTM, обученного на последовательностях
пользовательских действий. Их метод показал $AUC_ROC = 0.9449$, что является
на данный момент наилучшим значением метрики.

Последние работы в сфере NLP сделали большой прогресс в получении
"осмысленного" признакового представления текстовых данных основанные на
семантическом значении слов. Техники
word2Vec[@mikolovEfficientEstimationWord2013a], GloVe и ELMO позволяющие
получать признаковое описание слов в пространстве малой размерности,
позволили улучшить качество моделей для большинства NLP задач. Также в
конце 2018 года появилась модель BERT [@devlinBERTPretrainingDeep2019],
которая улучшила качество работы по 6 различным NLP задачам. Обученный
BERT также способен выдавать признаковое представление отдельных слов.
Также в [@noeverClassifierSuitesInsider2019] отмечалось,
сентимент-анализ содержимого писем и вебсайтов оказывает значительное
влияние на качество моделей.\