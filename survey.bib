
@article{petersDeepContextualizedWord2018,
	title = {Deep contextualized word representations},
	shorttitle = {{ELMO}},
	url = {http://arxiv.org/abs/1802.05365},
	abstract = {We introduce a new type of deep contextualized word representation that models both (1) complex characteristics of word use (e.g., syntax and semantics), and (2) how these uses vary across linguistic contexts (i.e., to model polysemy). Our word vectors are learned functions of the internal states of a deep bidirectional language model (biLM), which is pretrained on a large text corpus. We show that these representations can be easily added to existing models and signiﬁcantly improve the state of the art across six challenging NLP problems, including question answering, textual entailment and sentiment analysis. We also present an analysis showing that exposing the deep internals of the pre-trained network is crucial, allowing downstream models to mix different types of semi-supervision signals.},
	language = {en},
	urldate = {2019-03-20},
	journal = {arXiv:1802.05365 [cs]},
	author = {Peters, Matthew E. and Neumann, Mark and Iyyer, Mohit and Gardner, Matt and Clark, Christopher and Lee, Kenton and Zettlemoyer, Luke},
	month = feb,
	year = {2018},
	note = {arXiv: 1802.05365},
	keywords = {Computer Science - Computation and Language},
}

@misc{KakUEBAPomogaet,
	title = {Как {UEBA} помогает повышать уровень кибербезопасности},
	url = {https://habr.com/ru/company/roi4cio/blog/436082/},
	abstract = {Организации, которые хотят добавить расширенные аналитические возможности или возможности машинного обучения в свой арсенал ИТ-безопасности, имеют в своем распо...},
	language = {ru},
	urldate = {2019-12-25},
}

@article{chawlaSMOTESyntheticMinority2002,
	title = {{SMOTE}: {Synthetic} {Minority} {Over}-sampling {Technique}},
	volume = {16},
	issn = {1076-9757},
	shorttitle = {{SMOTE}},
	url = {https://www.jair.org/index.php/jair/article/view/10302},
	doi = {10.1613/jair.953},
	abstract = {An approach to the construction of classiﬁers from imbalanced datasets is described. A dataset is imbalanced if the classiﬁcation categories are not approximately equally represented. Often real-world data sets are predominately composed of “normal” examples with only a small percentage of “abnormal” or “interesting” examples. It is also the case that the cost of misclassifying an abnormal (interesting) example as a normal example is often much higher than the cost of the reverse error. Under-sampling of the majority (normal) class has been proposed as a good means of increasing the sensitivity of a classiﬁer to the minority class. This paper shows that a combination of our method of over-sampling the minority (abnormal) class and under-sampling the majority (normal) class can achieve better classiﬁer performance (in ROC space) than only under-sampling the majority class. This paper also shows that a combination of our method of over-sampling the minority class and under-sampling the majority class can achieve better classiﬁer performance (in ROC space) than varying the loss ratios in Ripper or class priors in Naive Bayes. Our method of over-sampling the minority class involves creating synthetic minority class examples. Experiments are performed using C4.5, Ripper and a Naive Bayes classiﬁer. The method is evaluated using the area under the Receiver Operating Characteristic curve (AUC) and the ROC convex hull strategy.},
	language = {en},
	urldate = {2019-12-24},
	journal = {Journal of Artificial Intelligence Research},
	author = {Chawla, N. V. and Bowyer, K. W. and Hall, L. O. and Kegelmeyer, W. P.},
	month = jun,
	year = {2002},
	pages = {321--357},
}

@inproceedings{saaudiInsiderThreatsDetection2019,
	title = {Insider {Threats} {Detection} using {CNN}-{LSTM} {Model}},
	shorttitle = {{CNN}-{LSTM}},
	author = {Saaudi, Ahmed and Al-Ibadi, Zaid and Tong, Yan and Farkas, Csilla},
	month = apr,
	year = {2019},
}

@article{leggAutomatedInsiderThreat2017,
	title = {Automated {Insider} {Threat} {Detection} {System} {Using} {User} and {Role}-{Based} {Profile} {Assessment}},
	volume = {11},
	issn = {1932-8184, 1937-9234, 2373-7816},
	url = {http://ieeexplore.ieee.org/document/7126970/},
	doi = {10.1109/JSYST.2015.2438442},
	abstract = {Organizations are experiencing an ever-growing concern of how to identify and defend against insider threats. Those who have authorized access to sensitive organizational data are placed in a position of power that could well be abused and could cause signiﬁcant damage to an organization. This could range from ﬁnancial theft and intellectual property theft to the destruction of property and business reputation. Traditional intrusion detection systems are neither designed nor capable of identifying those who act maliciously within an organization. In this paper, we describe an automated system that is capable of detecting insider threats within an organization. We deﬁne a tree-structure proﬁling approach that incorporates the details of activities conducted by each user and each job role and then use this to obtain a consistent representation of features that provide a rich description of the user’s behavior. Deviation can be assessed based on the amount of variance that each user exhibits across multiple attributes, compared against their peers. We have performed experimentation using ten synthetic data-driven scenarios and found that the system can identify anomalous behavior that may be indicative of a potential threat. We also show how our detection system can be combined with visual analytics tools to support further investigation by an analyst.},
	language = {en},
	number = {2},
	urldate = {2019-12-24},
	journal = {IEEE Systems Journal},
	author = {Legg, Philip A. and Buckley, Oliver and Goldsmith, Michael and Creese, Sadie},
	month = jun,
	year = {2017},
	pages = {503--512},
}

@article{koInsiderThreatDetection2017,
	title = {Insider threat detection and its future directions},
	volume = {12},
	issn = {1747-8405, 1747-8413},
	shorttitle = {another survey},
	url = {http://www.inderscience.com/link.php?id=84391},
	doi = {10.1504/IJSN.2017.084391},
	language = {en},
	number = {3},
	urldate = {2019-12-24},
	journal = {International Journal of Security and Networks},
	author = {Ko, Li Ling and Divakaran, Dinil Mon and Liau, Yung Siang and Thing, Vrizlynn L.L.},
	year = {2017},
	pages = {168},
}

@inproceedings{sanzgiriClassificationInsiderThreat2016,
	address = {Oak Ridge, TN, USA},
	title = {Classification of {Insider} {Threat} {Detection} {Techniques}},
	isbn = {978-1-4503-3752-6},
	url = {http://dl.acm.org/citation.cfm?doid=2897795.2897799},
	doi = {10.1145/2897795.2897799},
	language = {en},
	urldate = {2019-12-24},
	booktitle = {Proceedings of the 11th {Annual} {Cyber} and {Information} {Security} {Research} {Conference} on - {CISRC} '16},
	publisher = {ACM Press},
	author = {Sanzgiri, Ameya and Dasgupta, Dipankar},
	year = {2016},
	pages = {1--4}
}

@misc{veriatoInsiderThreatReport,
	title = {Insider {Threat} {Report} 2018},
	shorttitle = {haystax2018},
	url = {https://www.veriato.com/resources/whitepapers/insider-threat-report-2018},
	abstract = {Insider Threat Report 2018},
	language = {en},
	urldate = {2019-12-24},
	author = {Veriato},
}

@misc{InsiderThreatHuman,
	title = {Insider threat: {The} human element of cyberrisk {\textbar} {McKinsey}},
	shorttitle = {mckinsey},
	url = {https://www.mckinsey.com/business-functions/risk/our-insights/insider-threat-the-human-element-of-cyberrisk},
	abstract = {Cyber programs often miss the significant portion of risk generated from within, and tools for insider threat are blunt instruments. A new method can yield better results.},
	language = {en},
	urldate = {2019-12-24},
}

@incollection{klimtEnronCorpusNew2004,
	address = {Berlin, Heidelberg},
	title = {The {Enron} {Corpus}: {A} {New} {Dataset} for {Email} {Classification} {Research}},
	volume = {3201},
	isbn = {978-3-540-23105-9 978-3-540-30115-8},
	shorttitle = {The {Enron} {Corpus}},
	url = {http://link.springer.com/10.1007/978-3-540-30115-8_22},
	abstract = {Automated classiﬁcation of email messages into user-speciﬁc folders and information extraction from chronologically ordered email streams have become interesting areas in text learning research. However, the lack of large benchmark collections has been an obstacle for studying the problems and evaluating the solutions. In this paper, we introduce the Enron corpus as a new test bed. We analyze its suitability with respect to email folder prediction, and provide the baseline results of a stateof-the-art classiﬁer (Support Vector Machines) under various conditions, including the cases of using individual sections (From, To, Subject and body) alone as the input to the classiﬁer, and using all the sections in combination with regression weights.},
	language = {en},
	urldate = {2019-12-23},
	booktitle = {Machine {Learning}: {ECML} 2004},
	publisher = {Springer Berlin Heidelberg},
	author = {Klimt, Bryan and Yang, Yiming},
	editor = {Hutchison, David and Kanade, Takeo and Kittler, Josef and Kleinberg, Jon M. and Mattern, Friedemann and Mitchell, John C. and Naor, Moni and Nierstrasz, Oscar and Pandu Rangan, C. and Steffen, Bernhard and Sudan, Madhu and Terzopoulos, Demetri and Tygar, Dough and Vardi, Moshe Y. and Weikum, Gerhard and Boulicaut, Jean-François and Esposito, Floriana and Giannotti, Fosca and Pedreschi, Dino},
	year = {2004},
	doi = {10.1007/978-3-540-30115-8_22},
	pages = {217--226},
}

@article{gImageBasedFeatureRepresentation2019,
	title = {Image-{Based} {Feature} {Representation} for {Insider} {Threat} {Classification}},
	shorttitle = {image based threat detection},
	url = {http://arxiv.org/abs/1911.05879},
	abstract = {Insiders are the trusted entities in the organization, but poses threat to the with access to sensitive information network and resources. The insider threat detection is a well studied problem in security analytics. Identifying the features from data sources and using them with the right data analytics algorithms makes various kinds of threat analysis possible. The insider threat analysis is mainly done using the frequency based attributes extracted from the raw data available from data sources. In this paper, we propose an image-based feature representation of the daily resource usage pattern of users in the organization. The features extracted from the audit files of the organization are represented as gray scale images. Hence, these images are used to represent the resource access patterns and thereby the behavior of users. Classification models are applied to the representative images to detect anomalous behavior of insiders. The images are classified to malicious and non-malicious. The effectiveness of the proposed representation is evaluated using the CMU CERT data V4.2, and state-of-art image classification models like Mobilenet, VGG and ResNet. The experimental results showed improved accuracy. The comparison with existing works show a performance improvement in terms of high recall and precision values.},
	urldate = {2019-12-23},
	journal = {arXiv:1911.05879 [cs]},
	author = {G, Gayathri R. and Sajjanhar, Atul and Xiang, Yong},
	month = nov,
	year = {2019},
	note = {arXiv: 1911.05879},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Computer Science - Cryptography and Security},
}

@misc{yanRaymondinoInsiderThreatStreamReasoningUseCase2019,
	title = {raymondino/{InsiderThreat}-{StreamReasoningUseCase}},
	url = {https://github.com/raymondino/InsiderThreat-StreamReasoningUseCase},
	abstract = {This use case aims to leverage stream reasoning techniques and the concept of semantic importance to detect one attacking type of the insider threat -- data exfiltration},
	urldate = {2019-12-13},
	author = {Yan, Rui},
	month = jul,
	year = {2019},
	note = {original-date: 2016-06-09T22:08:18Z},
}

@inproceedings{glasserBridgingGapPragmatic2013,
	address = {San Francisco, CA},
	title = {Bridging the {Gap}: {A} {Pragmatic} {Approach} to {Generating} {Insider} {Threat} {Data}},
	isbn = {978-1-4799-0458-7},
	shorttitle = {{CERT} dataset},
	url = {http://ieeexplore.ieee.org/document/6565236/},
	doi = {10.1109/SPW.2013.37},
	abstract = {The threat of malicious insider activity continues to be of paramount concern in both the public and private sectors. Though there is great interest in advancing the state of the art in predicting and stopping these threats, the difﬁculty of obtaining suitable data for research, development, and testing remains a signiﬁcant hinderance. We outline the use of synthetic data to enable progress in one research program, while discussing the beneﬁts and limitations of synthetic insider threat data, the meaning of realism in this context, as well as future research directions.},
	language = {en},
	urldate = {2019-12-13},
	booktitle = {2013 {IEEE} {Security} and {Privacy} {Workshops}},
	publisher = {IEEE},
	author = {Glasser, Joshua and Lindauer, Brian},
	month = may,
	year = {2013},
	pages = {98--104},
}

@article{gamachchiInsiderThreatDetection2018,
	title = {Insider {Threat} {Detection} {Through} {Attributed} {Graph} {Clustering}},
	url = {http://arxiv.org/abs/1809.00231},
	abstract = {While most organizations continue to invest in traditional network defences, a formidable security challenge has been brewing within their own boundaries. Malicious insiders with privileged access in the guise of a trusted source have carried out many attacks causing far-reaching damage to financial stability, national security and brand reputation for both public and private sector organizations. Growing exposure and impact of the whistleblower community and concerns about job security with changing organizational dynamics has further aggravated this situation. The unpredictability of malicious attackers, as well as the complexity of malicious actions, necessitates the careful analysis of network, system and user parameters correlated with the insider threat problem. Thus it creates a high dimensional, heterogeneous data analysis problem in isolating suspicious users. This research work proposes an insider threat detection framework, which utilizes the attributed graph clustering techniques and outlier ranking mechanism for enterprise users. Empirical results also confirm the effectiveness of the method by achieving the best area under the curve value of 0.7648 for the receiver operating characteristic curve.},
	urldate = {2019-12-13},
	journal = {arXiv:1809.00231 [cs]},
	author = {Gamachchi, Anagi and Boztas, Serdar},
	month = sep,
	year = {2018},
	note = {arXiv: 1809.00231},
	keywords = {Computer Science - Cryptography and Security, Computer Science - Social and Information Networks, Insider Threat Detection},
}

@article{tausczikPsychologicalMeaningWords2010,
	title = {The {Psychological} {Meaning} of {Words}: {LIWC} and {Computerized} {Text} {Analysis} {Methods}},
	volume = {29},
	issn = {0261-927X, 1552-6526},
	shorttitle = {The {Psychological} {Meaning} of {Words}},
	url = {http://journals.sagepub.com/doi/10.1177/0261927X09351676},
	doi = {10.1177/0261927X09351676},
	language = {en},
	number = {1},
	urldate = {2020-01-09},
	journal = {Journal of Language and Social Psychology},
	author = {Tausczik, Yla R. and Pennebaker, James W.},
	month = mar,
	year = {2010},
	pages = {24--54},
}

@article{chattopadhyayScenarioBasedInsiderThreat2018,
	title = {Scenario-{Based} {Insider} {Threat} {Detection} {From} {Cyber} {Activities}},
	volume = {5},
	issn = {2329-924X, 2373-7476},
	url = {https://ieeexplore.ieee.org/document/8444978/},
	doi = {10.1109/TCSS.2018.2857473},
	number = {3},
	urldate = {2020-01-09},
	journal = {IEEE Transactions on Computational Social Systems},
	author = {Chattopadhyay, Pratik and Wang, Lipo and Tan, Yap-Peng},
	month = sep,
	year = {2018},
	pages = {660--675},
}

@incollection{yuanInsiderThreatDetection2018b,
	address = {Cham},
	title = {Insider {Threat} {Detection} with {Deep} {Neural} {Network}},
	volume = {10860},
	isbn = {978-3-319-93697-0 978-3-319-93698-7},
	shorttitle = {{LSTM}-{CNN}},
	url = {http://link.springer.com/10.1007/978-3-319-93698-7_4},
	urldate = {2020-01-09},
	booktitle = {Computational {Science} – {ICCS} 2018},
	publisher = {Springer International Publishing},
	author = {Yuan, Fangfang and Cao, Yanan and Shang, Yanmin and Liu, Yanbing and Tan, Jianlong and Fang, Binxing},
	editor = {Shi, Yong and Fu, Haohuan and Tian, Yingjie and Krzhizhanovskaya, Valeria V. and Lees, Michael Harold and Dongarra, Jack and Sloot, Peter M. A.},
	year = {2018},
	doi = {10.1007/978-3-319-93698-7_4},
	pages = {43--54},
}

@incollection{yuanAttentionBasedLSTMInsider2019,
	title = {Attention-{Based} {LSTM} for {Insider} {Threat} {Detection}},
	isbn = {9789811508707},
	shorttitle = {Attention-{Based} {LSTM}},
	abstract = {Insider threat is an important cyber security issue for businesses and organizations. Existing insider threat detection methods can be roughly divided into two categories, statistical features based detection methods and action sequence based detection methods. The first kind of method aggregates all actions that a user has performed over one day and uses these aggregated features to find insider threat. This kind of coarse-grained analytics of user behavior may miss anomalous behavior happening within that day. The second kind of method overcomes the coarser-grained problem and uses fine-grained detection to identify insider threat through user actions. However, the second kind of method considers all user operations to be equally important, without highlighting malicious user actions. To solve this problem, we present an attention-based Long Short-Term Memory (LSTM) model to detect insider threat. In our model, we apply the LSTM to capture the sequential information of user action sequence and employ an attention layer that can learn which user actions contribute more to insider threat detection. Extensive studies are conducted on the public dataset of insider threat. Our results demonstrate that the proposed model outperforms other deep learning models and can successfully identify insider threat.},
	author = {Yuan, Fangfang and Shang, Yanmin and Liu, Yanbing and Cao, Ya-Nan and Tan, Jianlong},
	month = nov,
	year = {2019},
	doi = {10.1007/978-981-15-0871-4_15},
	pages = {192--201},
}

@inproceedings{aldairiTrustAwareUnsupervised2019,
	title = {A {Trust} {Aware} {Unsupervised} {Learning} {Approach} for {Insider} {Threat} {Detection}},
	shorttitle = {Trust {Aware}},
	doi = {10.1109/IRI.2019.00027},
	author = {Aldairi, Maryam and Karimi, Leila and Joshi, James},
	month = jul,
	year = {2019},
	pages = {89--98},
}

@misc{PonemonReport20182018,
	title = {Ponemon {Report}: 2018 {Cost} of {Insider} {Threats} – {Global} {Organizations}},
	shorttitle = {ponemon2018},
	url = {https://www.observeit.com/ponemon-report-cost-of-insider-threats/},
	abstract = {2018 Cost of Insider Threats: Global Organizations},
	language = {en-US},
	urldate = {2020-01-09},
	journal = {ObserveIT},
	month = apr,
	year = {2018},
}

@inproceedings{brdiczkaProactiveInsiderThreat2012b,
	title = {Proactive {Insider} {Threat} {Detection} through {Graph} {Learning} and {Psychological} {Context}},
	shorttitle = {wowdataset},
	doi = {10.1109/SPW.2012.29},
	abstract = {The annual incidence of insider attacks continues to grow, and there are indications this trend will continue. While there are a number of existing tools that can accurately identify known attacks, these are reactive (as opposed to proactive) in their enforcement, and may be eluded by previously unseen, adversarial behaviors. This paper proposes an approach that combines Structural Anomaly Detection (SA) from social and information networks and Psychological Profiling (PP) of individuals. SA uses technologies including graph analysis, dynamic tracking, and machine learning to detect structural anomalies in large-scale information network data, while PP constructs dynamic psychological profiles from behavioral patterns. Threats are finally identified through a fusion and ranking of outcomes from SA and PP. The proposed approach is illustrated by applying it to a large data set from a massively multi-player online game, World of War craft (WoW). The data set contains behavior traces from over 350,000 characters observed over a period of 6 months. SA is used to predict if and when characters quit their guild (a player association with similarities to a club or workgroup in non-gaming contexts), possibly causing damage to these social groups. PP serves to estimate the five-factor personality model for all characters. Both threads show good results on the gaming data set and thus validate the proposed approach.},
	booktitle = {2012 {IEEE} {Symposium} on {Security} and {Privacy} {Workshops}},
	author = {Brdiczka, Oliver and Liu, Juan and Price, Bob and Shen, Jianqiang and Patil, Akshay and Chow, Richard and Bart, Eugene and Ducheneaut, Nicolas},
	month = may,
	year = {2012},
	note = {ISSN: null},
	keywords = {Insider Threat Detection, adversarial behaviors, behavioural sciences computing, computer games, Context, Data models, dynamic tracking, five-factor personality model, Games, gaming data, graph analysis, graph learning, Graph Learning, graph theory, Hidden Markov models, information networks, insider attacks, large-scale information network data, learning (artificial intelligence), machine learning, massively multiplayer online game, organisational aspects, organizations, proactive insider threat detection, psychological context, Psychological Context Modeling, psychological profiling, Psychological Profiling, psychology, Psychology, Semantics, social groups, Social network services, social networks, structural anomaly detection, Structural Anomaly Detection, World of Warcraft},
	pages = {142--149},
}

@misc{CostDataBreach,
	title = {Cost of a {Data} {Breach} {Study}},
	shorttitle = {Ponemon2016-2018},
	url = {https://www.ibm.com/security/data-breach},
	abstract = {Download the Cost of Data Breach Study to learn more about the global impact of a data breach and how data breaches affect individual nations.},
	language = {en-us},
	urldate = {2020-01-09},
}

@misc{2019CostDataREPLACE,
	title = {2019 {Cost} of a {Data} {Breach} {Report}{\textbar} {IBM} {Security}},
	copyright = {© Copyright IBM Corp. 2019},
	shorttitle = {Ponemon2019},
	url = {https://databreachcalculator.mybluemix.net},
	abstract = {What could a data breach cost you? Discover how much a data breach costs by industry and region. Explore the cost calculator and Cost of a Data Breach Report.},
	urldate = {2020-01-09},
	journal = {@IBMSecurity},
}

@misc{companyInsiderThreatReport,
	title = {Insider {Threat} {Report} - 2019},
	shorttitle = {haystax2019},
	url = {https://info.haystax.com/insider-threat-report-2019},
	language = {en},
	urldate = {2020-01-09},
	author = {Company, Haystax A. Fishtech Group},
}

@misc{GartnerReportMarket2019,
	title = {Gartner {Report}: “{Market} {Trends}: {UEBA} {Providers} {Must} {Embrace} {Enterprise} {Specialization}”},
	shorttitle = {Gartner {Report}},
	url = {https://www.observeit.com/gartner-report-market-trends-ueba-providers-must-embrace-enterprise-specialization/},
	abstract = {Check Out the Latest Gartner Report Highlighting Insider Threat},
	language = {en-US},
	urldate = {2020-01-09},
	journal = {ObserveIT},
	month = jun,
	year = {2019},
}

@misc{EmergingInsiderThreat2018,
	title = {Emerging {Insider} {Threat} {Detection} {Solutions}},
	shorttitle = {gartner solutions2018},
	url = {https://blogs.gartner.com/avivah-litan/2018/04/05/insider-threat-detection-replaces-dying-dlp/},
	abstract = {Gartner inquiries on insider threat detection are up over 50\% YOY for the last two months, and our clients are seeking solutions – both technical and non-technical – for a problem that legacy solutions are not effectively addressing. The Many Flavors of Insider Threats Insider threats come in many flavors as depicted below in Figure 1, …},
	language = {en},
	urldate = {2020-01-09},
	journal = {Avivah Litan},
	month = apr,
	year = {2018},
}

@article{sadowskiMarketGuideUser,
	title = {Market {Guide} for {User} and {Entity} {Behavior} {Analytics}},
	language = {en},
	author = {Sadowski, Gorka and Litan, Avivah and Bussa, Toby and Phillips, Tricia},
	pages = {22},
}

@misc{CERTInsiderThreat,
	title = {The {CERT} {Insider} {Threat} {Database}},
	url = {https://insights.sei.cmu.edu/insider-threat/2011/08/the-cert-insider-threat-database.html},
	urldate = {2020-01-12},
}

@misc{loDistanceMeasurementMethods2018,
	type = {Research {Article}},
	title = {Distance {Measurement} {Methods} for {Improved} {Insider} {Threat} {Detection}},
	url = {https://new.hindawi.com/journals/scn/2018/5906368/},
	abstract = {Insider threats are a considerable problem within cyber security and it is often difficult to detect these threats using signature detection. Increasing machine learning can provide a solution, but these methods often fail to take into account changes of behaviour of users. This work builds on a published method of detecting insider threats and applies Hidden Markov method on a CERT data set (CERT r4.2) and analyses a number of distance vector methods (Damerau\&\#x2013;Levenshtein Distance, Cosine Distance, and Jaccard Distance) in order to detect changes of behaviour, which are shown to have success in determining different insider threats.},
	language = {en},
	urldate = {2020-01-12},
	journal = {Security and Communication Networks},
	author = {Lo, Owen and Buchanan, William J. and Griffiths, Paul and Macfarlane, Richard},
	year = {2018},
	doi = {https://doi.org/10.1155/2018/5906368},
}

@misc{2016CostInsider,
	title = {2016 {Cost} of {Insider} {Threats} {Report}},
	shorttitle = {Ponemon2016},
	url = {https://www.dtexsystems.com/resources/white-papers/2016-cost-of-insider-threats-report/},
	abstract = {Dtex partnered with the Ponemon Institute to determine the true financial burden of insider threats in the 2016 Cost of Insider Threats report.},
	language = {en-US},
	urldate = {2020-01-11},
	journal = {Dtex Systems - Enterprise User Intelligence},
}

@inproceedings{rashidNewTakeDetecting2016,
	address = {Vienna, Austria},
	title = {A {New} {Take} on {Detecting} {Insider} {Threats}: {Exploring} the {Use} of {Hidden} {Markov} {Models}},
	isbn = {978-1-4503-4571-2},
	shorttitle = {A {New} {Take} on {Detecting} {Insider} {Threats}},
	url = {http://dl.acm.org/citation.cfm?doid=2995959.2995964},
	doi = {10.1145/2995959.2995964},
	abstract = {The threat that malicious insiders pose towards organisations is a signiﬁcant problem. In this paper, we investigate the task of detecting such insiders through a novel method of modelling a user’s normal behaviour in order to detect anomalies in that behaviour which may be indicative of an attack. Speciﬁcally, we make use of Hidden Markov Models to learn what constitutes normal behaviour, and then use them to detect signiﬁcant deviations from that behaviour. Our results show that this approach is indeed successful at detecting insider threats, and in particular is able to accurately learn a user’s behaviour. These initial tests improve on existing research and may provide a useful approach in addressing this part of the insider-threat challenge.},
	language = {en},
	urldate = {2020-01-11},
	booktitle = {Proceedings of the 2016 {International} {Workshop} on {Managing} {Insider} {Security} {Threats} - {MIST} '16},
	publisher = {ACM Press},
	author = {Rashid, Tabish and Agrafiotis, Ioannis and Nurse, Jason R.C.},
	year = {2016},
	pages = {47--56},
}

@article{mikolovEfficientEstimationWord2013a,
	title = {Efficient {Estimation} of {Word} {Representations} in {Vector} {Space}},
	url = {http://arxiv.org/abs/1301.3781},
	abstract = {We propose two novel model architectures for computing continuous vector representations of words from very large data sets. The quality of these representations is measured in a word similarity task, and the results are compared to the previously best performing techniques based on different types of neural networks. We observe large improvements in accuracy at much lower computational cost, i.e. it takes less than a day to learn high quality word vectors from a 1.6 billion words data set. Furthermore, we show that these vectors provide state-of-the-art performance on our test set for measuring syntactic and semantic word similarities.},
	urldate = {2020-01-10},
	journal = {arXiv:1301.3781 [cs]},
	author = {Mikolov, Tomas and Chen, Kai and Corrado, Greg and Dean, Jeffrey},
	month = sep,
	year = {2013},
	note = {arXiv: 1301.3781},
	keywords = {Computer Science - Computation and Language},
}

@article{homoliakInsightInsidersIT2019,
	title = {Insight into {Insiders} and {IT}: {A} {Survey} of {Insider} {Threat} {Taxonomies}, {Analysis}, {Modeling}, and {Countermeasures}},
	volume = {52},
	issn = {03600300},
	shorttitle = {Insight into {Insiders} and {IT}},
	url = {http://arxiv.org/abs/1805.01612},
	doi = {10.1145/3303771},
	abstract = {Insider threats are one of today's most challenging cybersecurity issues that are not well addressed by commonly employed security solutions. Despite several scientific works published in this domain, we argue that the field can benefit from the proposed structural taxonomy and novel categorization of research that contribute to the organization and disambiguation of insider threat incidents and the defense solutions used against them. The objective of our categorization is to systematize knowledge in insider threat research, while leveraging existing grounded theory method for rigorous literature review. The proposed categorization depicts the workflow among particular categories that include: 1) Incidents and datasets, 2) Analysis of attackers, 3) Simulations, and 4) Defense solutions. Special attention is paid to the definitions and taxonomies of the insider threat; we present a structural taxonomy of insider threat incidents, which is based on existing taxonomies and the 5W1H questions of the information gathering problem. Our survey will enhance researchers' efforts in the domain of insider threat, because it provides: a) a novel structural taxonomy that contributes to orthogonal classification of incidents and defining the scope of defense solutions employed against them, b) an updated overview on publicly available datasets that can be used to test new detection solutions against other works, c) references of existing case studies and frameworks modeling insiders' behaviors for the purpose of reviewing defense solutions or extending their coverage, and d) a discussion of existing trends and further research directions that can be used for reasoning in the insider threat domain.},
	number = {2},
	urldate = {2020-01-10},
	journal = {ACM Computing Surveys},
	author = {Homoliak, Ivan and Toffalini, Flavio and Guarnizo, Juan and Elovici, Yuval and Ochoa, Martín},
	month = apr,
	year = {2019},
	note = {arXiv: 1805.01612},
	keywords = {Computer Science - Cryptography and Security, Computer Science - Computers and Society},
	pages = {1--40},
}

@inproceedings{luInsiderThreatDetection2019,
	address = {Sydney, NSW, Australia},
	title = {Insider {Threat} {Detection} with {Long} {Short}-{Term} {Memory}},
	isbn = {978-1-4503-6603-8},
	url = {http://dl.acm.org/citation.cfm?doid=3290688.3290692},
	doi = {10.1145/3290688.3290692},
	language = {en},
	urldate = {2020-01-10},
	booktitle = {Proceedings of the {Australasian} {Computer} {Science} {Week} {Multiconference} on - {ACSW} 2019},
	publisher = {ACM Press},
	author = {Lu, Jiuming and Wong, Raymond K.},
	year = {2019},
	pages = {1--10},
}

@article{noeverClassifierSuitesInsider2019,
	title = {Classifier {Suites} for {Insider} {Threat} {Detection}},
	url = {http://arxiv.org/abs/1901.10948},
	abstract = {Better methods to detect insider threats need new anticipatory analytics to capture risky behavior prior to losing data. In search of the best overall classifier, this work empirically scores 88 machine learning algorithms in 16 major families. We extract risk features from the large CERT dataset, which blends real network behavior with individual threat narratives. We discover the predictive importance of measuring employee sentiment. Among major classifier families tested on CERT, the random forest algorithms offer the best choice, with different implementations scoring over 98\% accurate. In contrast to more obscure or black-box alternatives, random forests are ensembles of many decision trees and thus offer a deep but human-readable set of detection rules ({\textgreater}2000 rules). We address performance rankings by penalizing long execution times against higher median accuracies using cross-fold validation. We address the relative rarity of threats as a case of low signal-to-noise ({\textless} 0.02\% malicious to benign activities), and then train on both under-sampled and over-sampled data which is statistically balanced to identify nefarious actors.},
	urldate = {2020-01-10},
	journal = {arXiv:1901.10948 [cs, stat]},
	author = {Noever, David},
	month = jan,
	year = {2019},
	note = {arXiv: 1901.10948},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Cryptography and Security},
}

@article{devlinBERTPretrainingDeep2019,
	title = {{BERT}: {Pre}-training of {Deep} {Bidirectional} {Transformers} for {Language} {Understanding}},
	shorttitle = {{BERT}},
	url = {http://arxiv.org/abs/1810.04805},
	abstract = {We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models, BERT is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications. BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5\% (7.7\% point absolute improvement), MultiNLI accuracy to 86.7\% (4.6\% absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement).},
	urldate = {2020-01-10},
	journal = {arXiv:1810.04805 [cs]},
	author = {Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
	month = may,
	year = {2019},
	note = {arXiv: 1810.04805},
	keywords = {Computer Science - Computation and Language},
}

@article{liuRoBERTaRobustlyOptimized2019,
	title = {{RoBERTa}: {A} {Robustly} {Optimized} {BERT} {Pretraining} {Approach}},
	shorttitle = {{RoBERTa}},
	url = {http://arxiv.org/abs/1907.11692},
	abstract = {Language model pretraining has led to significant performance gains but careful comparison between different approaches is challenging. Training is computationally expensive, often done on private datasets of different sizes, and, as we will show, hyperparameter choices have significant impact on the final results. We present a replication study of BERT pretraining (Devlin et al., 2019) that carefully measures the impact of many key hyperparameters and training data size. We find that BERT was significantly undertrained, and can match or exceed the performance of every model published after it. Our best model achieves state-of-the-art results on GLUE, RACE and SQuAD. These results highlight the importance of previously overlooked design choices, and raise questions about the source of recently reported improvements. We release our models and code.},
	urldate = {2020-01-10},
	journal = {arXiv:1907.11692 [cs]},
	author = {Liu, Yinhan and Ott, Myle and Goyal, Naman and Du, Jingfei and Joshi, Mandar and Chen, Danqi and Levy, Omer and Lewis, Mike and Zettlemoyer, Luke and Stoyanov, Veselin},
	month = jul,
	year = {2019},
	note = {arXiv: 1907.11692},
	keywords = {Computer Science - Computation and Language},
}

@article{lanALBERTLiteBERT2019,
	title = {{ALBERT}: {A} {Lite} {BERT} for {Self}-supervised {Learning} of {Language} {Representations}},
	shorttitle = {{ALBERT}},
	url = {http://arxiv.org/abs/1909.11942},
	abstract = {Increasing model size when pretraining natural language representations often results in improved performance on downstream tasks. However, at some point further model increases become harder due to GPU/TPU memory limitations, longer training times, and unexpected model degradation. To address these problems, we present two parameter-reduction techniques to lower memory consumption and increase the training speed of BERT. Comprehensive empirical evidence shows that our proposed methods lead to models that scale much better compared to the original BERT. We also use a self-supervised loss that focuses on modeling inter-sentence coherence, and show it consistently helps downstream tasks with multi-sentence inputs. As a result, our best model establishes new state-of-the-art results on the GLUE, RACE, and SQuAD benchmarks while having fewer parameters compared to BERT-large.The code and the pretrained models are available at https://github.com/google-research/google-research/tree/master/albert.},
	urldate = {2020-01-10},
	journal = {arXiv:1909.11942 [cs]},
	author = {Lan, Zhenzhong and Chen, Mingda and Goodman, Sebastian and Gimpel, Kevin and Sharma, Piyush and Soricut, Radu},
	month = oct,
	year = {2019},
	note = {arXiv: 1909.11942},
	keywords = {Computer Science - Computation and Language, Computer Science - Artificial Intelligence},
}

@misc{StatisticalMethodsComputer,
	title = {Statistical {Methods} for {Computer} {Intrusion} {Detection}},
	url = {http://www.schonlau.net/intrusion.html},
	urldate = {2020-01-13},
}

@inproceedings{harilalTWOSDatasetMalicious2017,
	title = {{TWOS}: {A} {Dataset} of {Malicious} {Insider} {Threat} {Behavior} {Based} on a {Gamified} {Competition}},
	shorttitle = {{TWOS}},
	doi = {10.1145/3139923.3139929},
	abstract = {In this paper we present the design and outcome of a gamified competition that was devised in order to obtain a dataset containing realistic instances of insider threats. The competition simulated user interactions in/among competing companies, where two types of behaviors (normal and malicious) were incentivized. For the case of malicious behavior, we designed sessions for two types of insider threats (masqueraders and traitors). The game involved the participation of 6 teams consisting of 4 students who competed with each other for a period of 5 days, while their activities were monitored considering several heterogeneous sources (mouse, keyboard, process and file-system monitor, network traffic, emails and login/logout). In sum, we obtained 320 hours of active participation that included 18 hours of masquerader data and at least two instances of traitor data. Additionally to malicious behaviors, the students explored various defensive and offensive strategies, such as denial of service attacks and obfuscation techniques, in an effort to get ahead in the competition. The TWOS dataset is publicly accessible for further research purposes.},
	booktitle = {{MIST} '17},
	author = {Harilal, Athul and Toffalini, Flavio and Castellanos, John Henry and Guarnizo, Juan and Homoliak, Ivan and Ochoa, Martín},
	year = {2017},
	keywords = {Computer mouse, Denial-of-service attack, Email, Gamification, Insider threat, Interaction, Login, Malware, Network traffic control, System monitor}
}

@incollection{salemModelingUserSearch2011,
	address = {Berlin, Heidelberg},
	title = {Modeling {User} {Search} {Behavior} for {Masquerade} {Detection}},
	volume = {6961},
	isbn = {978-3-642-23643-3 978-3-642-23644-0},
	url = {http://link.springer.com/10.1007/978-3-642-23644-0_10},
	language = {en},
	urldate = {2020-01-13},
	booktitle = {Recent {Advances} in {Intrusion} {Detection}},
	publisher = {Springer Berlin Heidelberg},
	author = {Salem, Malek Ben and Stolfo, Salvatore J.},
	editor = {Sommer, Robin and Balzarotti, Davide and Maier, Gregor},
	year = {2011},
	doi = {10.1007/978-3-642-23644-0_10},
	pages = {181--200},
}

@article{caminaWindowsUsersIntruderSimulations2014,
	series = {Methods and {Applications} of {Artificial} and {Computational} {Intelligence}},
	title = {The {Windows}-{Users} and -{Intruder} simulations {Logs} dataset ({WUIL}): {An} experimental framework for masquerade detection mechanisms},
	volume = {41},
	issn = {0957-4174},
	shorttitle = {The {Windows}-{Users} and -{Intruder} simulations {Logs} dataset ({WUIL})},
	url = {http://www.sciencedirect.com/science/article/pii/S0957417413006349},
	doi = {10.1016/j.eswa.2013.08.022},
	abstract = {We introduce a new masquerade dataset, called Windows-Users and -Intruder simulations Logs (WUIL), which, unlike existing datasets, involves more faithful masquerade attempts. While building WUIL, we have worked under the hypothesis that the way in which a user navigates her file system structure can neatly separate a masquerade attack. Thus, departing from standard practice, we state that it is not a user action, but the object upon which the action is carried out what distinguishes user participation. We shall argue that this approach, based on file system navigation provides a richer means, and at a higher-level of abstraction, for building novel models for masquerade detection. We shall devote an important part of this paper to describe WUIL’s content: what information about user activity is stored and how it is represented; prominent characteristics of the participant users; the kinds of masquerade attacks to be timely detected; and the way they have been simulated. We shall argue that WUIL provides reliable data for experimenting on close to real-life instances of masquerade detection, as well as for conducting fair comparisons on rival detection mechanisms, hoping it will be of use to the research community. As a side contribution of this paper, we use WUIL to conduct a simple comparison of two masquerade detection methods: one based on SVM, and the other based on KNN. While this comparison experiment is not central to the paper, we expect it to motivate research exploring deeper the masquerade detection problem, and spreading the use of WUIL. In a similar vein, we provide directions for further research, hinting on how to use the features contained in WUIL, and hoping others would find them appealing.},
	language = {en},
	number = {3},
	urldate = {2020-01-13},
	journal = {Expert Systems with Applications},
	author = {Camiña, J. Benito and Hernández-Gracidas, Carlos and Monroy, Raúl and Trejo, Luis},
	month = feb,
	year = {2014},
	keywords = {Computer security, Masquerade dataset, Masquerade detection},
	pages = {919--930},
}

@misc{UCIMachineLearning,
	title = {{UCI} {Machine} {Learning} {Repository}: {UNIX} {User} {Data} {Data} {Set}},
	url = {https://archive.ics.uci.edu/ml/datasets/UNIX+User+Data},
	urldate = {2020-01-13},
}

@article{greenbergUsingUNIXCollected1988,
	title = {Using {UNIX}: collected traces of 168 users},
	shorttitle = {Using {UNIX}},
	author = {Greenberg, Saul},
	month = jan,
	year = {1988},
}

@misc{2019InsiderThreat,
	title = {2019 {Insider} {Threat} {Report}},
	url = {https://enterprise.verizon.com/resources/reports/insider-threat-report/},
	abstract = {Read the Insider Threat Report to learn about the primary causes of internal breaches. See how you can work with Verizon Enterprise Solutions to develop an insider threat program to protect against malicious actors who may already be inside your organization.},
	language = {en},
	urldate = {2020-01-18},
	journal = {Verizon Enterprise},
}

@misc{InsiderThreatTest,
	title = {Insider {Threat} {Test} {Dataset}},
	url = {https://resources.sei.cmu.edu/library/asset-view.cfm?assetid=508099},
	language = {en},
	urldate = {2020-02-07},
	file = {Snapshot:C\:\\Users\\admin\\Zotero\\storage\\9QZG84QJ\\asset-view.html:text/html}
}

@incollection{NEURIPS2019_9015,
title = {PyTorch: An Imperative Style, High-Performance Deep Learning Library},
author = {Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and Desmaison, Alban and Kopf, Andreas and Yang, Edward and DeVito, Zachary and Raison, Martin and Tejani, Alykhan and Chilamkurthy, Sasank and Steiner, Benoit and Fang, Lu and Bai, Junjie and Chintala, Soumith},
booktitle = {Advances in Neural Information Processing Systems 32},
editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
pages = {8024--8035},
year = {2019},
publisher = {Curran Associates, Inc.},
url = {http://papers.neurips.cc/paper/9015-pytorch-an-imperative-style-high-performance-deep-learning-library.pdf}
}

@article{scikit-learn,
 title={Scikit-learn: Machine Learning in {P}ython},
 author={Pedregosa, F. and Varoquaux, G. and Gramfort, A. and Michel, V.
         and Thirion, B. and Grisel, O. and Blondel, M. and Prettenhofer, P.
         and Weiss, R. and Dubourg, V. and Vanderplas, J. and Passos, A. and
         Cournapeau, D. and Brucher, M. and Perrot, M. and Duchesnay, E.},
 journal={Journal of Machine Learning Research},
 volume={12},
 pages={2825--2830},
 year={2011}
}

@InProceedings{ mckinney-proc-scipy-2010,
  author    = { Wes McKinney },
  title     = { Data Structures for Statistical Computing in Python },
  booktitle = { Proceedings of the 9th Python in Science Conference },
  pages     = { 51 - 56 },
  year      = { 2010 },
  editor    = { St\'efan van der Walt and Jarrod Millman }
}

@Manual{ dask,
  title = {Dask: Library for dynamic task scheduling},
  author = {{Dask Development Team}},
  year = {2016},
  url = {https://dask.org},
}

@inproceedings{rehurek_lrec,
      title = {{Software Framework for Topic Modelling with Large Corpora}},
      author = {Radim {\v R}eh{\r u}{\v r}ek and Petr Sojka},
      booktitle = {{Proceedings of the LREC 2010 Workshop on New
           Challenges for NLP Frameworks}},
      pages = {45--50},
      year = 2010,
      month = May,
      day = 22,
      publisher = {ELRA},
      address = {Valletta, Malta},
      note={\url{http://is.muni.cz/publication/884893/en}},
      language={English}
}

@misc{wandb,
title = {Experiment Tracking with Weights and Biases},
year = {2020},
note = {Software available from wandb.com},
url={https://www.wandb.com/},
author = {Biewald, Lukas},
}

@article{srivastavaDropoutSimpleWay,
	title = {Dropout: {A} {Simple} {Way} to {Prevent} {Neural} {Networks} from {Overﬁtting}},
	abstract = {Deep neural nets with a large number of parameters are very powerful machine learning systems. However, overﬁtting is a serious problem in such networks. Large networks are also slow to use, making it diﬃcult to deal with overﬁtting by combining the predictions of many diﬀerent large neural nets at test time. Dropout is a technique for addressing this problem. The key idea is to randomly drop units (along with their connections) from the neural network during training. This prevents units from co-adapting too much. During training, dropout samples from an exponential number of diﬀerent “thinned” networks. At test time, it is easy to approximate the eﬀect of averaging the predictions of all these thinned networks by simply using a single unthinned network that has smaller weights. This signiﬁcantly reduces overﬁtting and gives major improvements over other regularization methods. We show that dropout improves the performance of neural networks on supervised learning tasks in vision, speech recognition, document classiﬁcation and computational biology, obtaining state-of-the-art results on many benchmark data sets.},
	language = {en},
	author = {Srivastava, Nitish and Hinton, Geoﬀrey and Krizhevsky, Alex and Sutskever, Ilya and Salakhutdinov, Ruslan},
	pages = {30},
	file = {Srivastava и др. - Dropout A Simple Way to Prevent Neural Networks f.pdf:C\:\\Users\\admin\\Zotero\\storage\\YNZFD8YJ\\Srivastava и др. - Dropout A Simple Way to Prevent Neural Networks f.pdf:application/pdf}
}

@article{yueImbalancedMalwareImages2017a,
	title = {Imbalanced {Malware} {Images} {Classification}: a {CNN} based {Approach}},
	shorttitle = {Imbalanced {Malware} {Images} {Classification}},
	url = {http://arxiv.org/abs/1708.08042},
	abstract = {Deep convolutional neural networks (CNNs) can be applied to malware binary detection through images classification. The performance, however, is degraded due to the imbalance of malware families (classes). To mitigate this issue, we propose a simple yet effective weighted softmax loss which can be employed as the final layer of deep CNNs. The original softmax loss is weighted, and the weight value can be determined according to class size. A scaling parameter is also included in computing the weight. Proper selection of this parameter has been studied and an empirical option is given. The weighted loss aims at alleviating the impact of data imbalance in an end-to-end learning fashion. To validate the efficacy, we deploy the proposed weighted loss in a pre-trained deep CNN model and fine-tune it to achieve promising results on malware images classification. Extensive experiments also indicate that the new loss function can fit other typical CNNs with an improved classification performance.},
	urldate = {2020-04-15},
	journal = {arXiv:1708.08042 [cs, stat]},
	author = {Yue, Songqing},
	month = aug,
	year = {2017},
	note = {arXiv: 1708.08042},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {arXiv Fulltext PDF:C\:\\Users\\admin\\Zotero\\storage\\UNHURRC3\\Yue - 2017 - Imbalanced Malware Images Classification a CNN ba.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\admin\\Zotero\\storage\\2ZD5SYJE\\1708.html:text/html}
}

@article{ioffeBatchNormalizationAccelerating2015,
	title = {Batch {Normalization}: {Accelerating} {Deep} {Network} {Training} by {Reducing} {Internal} {Covariate} {Shift}},
	shorttitle = {Batch {Normalization}},
	url = {http://arxiv.org/abs/1502.03167},
	abstract = {Training Deep Neural Networks is complicated by the fact that the distribution of each layer's inputs changes during training, as the parameters of the previous layers change. This slows down the training by requiring lower learning rates and careful parameter initialization, and makes it notoriously hard to train models with saturating nonlinearities. We refer to this phenomenon as internal covariate shift, and address the problem by normalizing layer inputs. Our method draws its strength from making normalization a part of the model architecture and performing the normalization for each training mini-batch. Batch Normalization allows us to use much higher learning rates and be less careful about initialization. It also acts as a regularizer, in some cases eliminating the need for Dropout. Applied to a state-of-the-art image classification model, Batch Normalization achieves the same accuracy with 14 times fewer training steps, and beats the original model by a significant margin. Using an ensemble of batch-normalized networks, we improve upon the best published result on ImageNet classification: reaching 4.9\% top-5 validation error (and 4.8\% test error), exceeding the accuracy of human raters.},
	urldate = {2020-04-15},
	journal = {arXiv:1502.03167 [cs]},
	author = {Ioffe, Sergey and Szegedy, Christian},
	month = mar,
	year = {2015},
	note = {arXiv: 1502.03167},
	keywords = {Computer Science - Machine Learning},
	file = {arXiv Fulltext PDF:C\:\\Users\\admin\\Zotero\\storage\\3DMMTPJI\\Ioffe and Szegedy - 2015 - Batch Normalization Accelerating Deep Network Tra.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\admin\\Zotero\\storage\\97SH6RKF\\1502.html:text/html}
}

@inproceedings{leEvaluatingInsiderThreat2018,
	address = {San Francisco, CA},
	title = {Evaluating {Insider} {Threat} {Detection} {Workflow} {Using} {Supervised} and {Unsupervised} {Learning}},
	isbn = {978-1-5386-8276-0},
	url = {https://ieeexplore.ieee.org/document/8424659/},
	doi = {10.1109/SPW.2018.00043},
	abstract = {Insider threat is a prominent cyber-security danger faced by organizations and companies. In this research, we study and evaluate an insider threat detection workﬂow using supervised and unsupervised learning algorithms. To this end, we study data exploration and analysis, anomaly detection and malicious behaviour classiﬁcation on a publicly available data set. We evaluate several supervised and unsupervised learning algorithms - HMM, SOM, and DT - using this workﬂow.},
	language = {en},
	urldate = {2020-10-21},
	booktitle = {2018 {IEEE} {Security} and {Privacy} {Workshops} ({SPW})},
	publisher = {IEEE},
	author = {Le, Duc C. and Zincir-Heywood, A. Nur},
	month = may,
	year = {2018},
	pages = {270--275},
	file = {Le and Zincir-Heywood - 2018 - Evaluating Insider Threat Detection Workflow Using.pdf:C\:\\Users\\admin\\Zotero\\storage\\HG9JLTI5\\Le and Zincir-Heywood - 2018 - Evaluating Insider Threat Detection Workflow Using.pdf:application/pdf}
}


@article{karpathyDeepVisualSemanticAlignments2015,
	title = {Deep {Visual}-{Semantic} {Alignments} for {Generating} {Image} {Descriptions}},
	url = {http://arxiv.org/abs/1412.2306},
	abstract = {We present a model that generates natural language descriptions of images and their regions. Our approach leverages datasets of images and their sentence descriptions to learn about the inter-modal correspondences between language and visual data. Our alignment model is based on a novel combination of Convolutional Neural Networks over image regions, bidirectional Recurrent Neural Networks over sentences, and a structured objective that aligns the two modalities through a multimodal embedding. We then describe a Multimodal Recurrent Neural Network architecture that uses the inferred alignments to learn to generate novel descriptions of image regions. We demonstrate that our alignment model produces state of the art results in retrieval experiments on Flickr8K, Flickr30K and MSCOCO datasets. We then show that the generated descriptions significantly outperform retrieval baselines on both full images and on a new dataset of region-level annotations.},
	urldate = {2020-10-22},
	journal = {arXiv:1412.2306 [cs]},
	author = {Karpathy, Andrej and Fei-Fei, Li},
	month = apr,
	year = {2015},
	note = {arXiv: 1412.2306},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	file = {arXiv Fulltext PDF:C\:\\Users\\admin\\Zotero\\storage\\FJN5N29P\\Karpathy and Fei-Fei - 2015 - Deep Visual-Semantic Alignments for Generating Ima.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\admin\\Zotero\\storage\\KZFZYSLJ\\1412.html:text/html}
}
