\chapter{План решения задачи}

\begin{enumerate}
    \item Воспрозвести результаты статьи \cite{yuanInsiderThreatDetection2018b}, так как эта работа имеет наилучшие представленные результаты на наборе данных CERT. На данный момент статья уже воспроизведена, для улучшения качества классификации были подобраны гиперпараметры, добавлены слои BatchNormalization \cite{ioffeBatchNormalizationAccelerating2015} и Dropout \cite{srivastavaDropoutSimpleWay}, добавлена ребалансировка весов в функции потерь. На основе полученной модели проводятся все последующие эксперименты.
    \item Так как все современные работы не используют контентные данные набора данных CERT, следует провести эксперименты с ними. Этот этап выполнен. Для обработки контентных данных использовалась обработка алгоритмом LDA для тематического представления текстов. Добавление контентных данных не улучшило качество классификации.
    \item Добавить агрегированные статистики по последовательностям, как описано в \cite{leEvaluatingInsiderThreat2018}. Сложность данного этапа заключается в том, что для обучения LSTM-модели невозможно напрямую добавить такой вид данных. Чтобы обойти это, можно использовать подход, описанный в \cite{karpathyDeepVisualSemanticAlignments2015}, который заключается в инициализации скрытого состояния LSTM на основе произвольного входного вектора.
    \item Добавить Attention-слой в LSTM-кодировщик. Как показано в \cite{yuanInsiderThreatDetection2018b}, это позволит улучшить качество классификации. Необходимо провести эксперимент, сможет ли это улучшить в случае использования сверточного классификатора
    \item Использовать BERT \cite{devlinBERTPretrainingDeep2019}. На данный момент модели из семейства BERT дают наилучшее качество практически во всех задачах обработки естественных языков. Можно попробовать адаптировать BERT для анализа последовательностей пользовательских действий.
\end{enumerate}