\section{Обзор моделей}

Синтетический набор данных разработанный подразделением CERT Carnegie Melon University пользуется очень большой популярностью в исследованиях на данную тему. Поэтому, по умолчанию, во всех приведенных статьях ниже используется набор данных CERT версии 4.2. Также по умолчанию содержимое писем, файлов и вебсайтов из данного набора данных не используется.\\

В работе \cite{rashidNewTakeDetecting2016} используется скрытая марковская модель (Hidden Markov Model - \textbf{HMM}). Скрытая марковская модель представляет собой обычную марковскую модель, в которой модель выводит некоторый символ каждый раз перед переходом в следующее состояние. Модель называется скрытой, поскольку мы наблюдаем только выходы модели, а последовательность переходов состояний скрыта от нас.\\
В данной работе все действия пользователей кодируются числами. Затем действия собираются отдельно для каждого пользователя и сортируются по времени. На первых пяти неделях модель обучается (используется предположение, что за это время инсайдерского поведения не было), для последующих недель модель предсказывает вероятность аномальности поведения и только потом обучается. Поведение за неделю считается аномальным, если оно превышает заданный порог.\\
Эксперименты на CERT 4.2 после подбора гиперпараметров показали AUC ROC $0.83$.\\

В \cite{aldairiTrustAwareUnsupervised2019} также применяется метод обучения без учителя и задача обнаружения инсайдерских угроз ставится как задача обнаружения аномалий. В этой работе сравниваются два классических метода нахождения аномалий: Isolation Forest и One Class SVM. Работа проводилась на наборе данных CERT. Моделям на вход подавались данные агрегированные по разным временным периодам - дням, месяцам, полугодиям и годам. Также в качестве дополнительного признака используется trust score (показатель доверия), который означает оценку аномальности пользователя для предыдущего периода. Авторы показывают, что этот признак заметно улучшает точность предсказаний моделей, особенно в случаях моделей, в которых данные агрегируются по малым периодам.\\

В статье \cite{luInsiderThreatDetection2019} применяется рекуррентная нейронная сеть LSTM для поиска аномалий в поведении пользователей. В работе проведены эксперименты, которые показывают, что LSTM действительно обучается паттернам поведения пользователей и находить аномальное поведение. Наилучший результат при подборе гиперпараметров: точность - $0.84$ и полнота - $0.60$.\\
В статье приводится предположение, что некоторые случаи, в которых модель ошибочно не распознала аномальное поведение, можно разрешить с помощью анализа контента.

В \cite{noeverClassifierSuitesInsider2019} было испробовано множество различных семейств алгоритмов машинного обучения. В этой статье приводится к заключению, что алгоритмы случайного леса и бустинга показывают наилучшие результаты. Важно отметить, что они в качестве признаков также использовали сентимент-анализ текста электронной почты и содержания посещенных сайтов.

При применении моделей машинного обучения качество моделей очень сильно зависит от признаков, которые были вручную сгенерированы исследователями. Однако в последнее время наблюдается очень большой интерес к нейронным сетям, в том числе из-за того, что они способны автоматически выучивать хорошее признаковое представление данных. Поэтому и в данной теме множество последних работ использует нейросети.\\

В работе \cite{brdiczkaProactiveInsiderThreat2012b} используется информация о социальном графе для нахождения аномалий в нем и поведенческая информация пользователей для психологического профилирования. Интересно отметить, что в данной работе в качестве данных использовались данные из популярной онлайн многопользовательской игры World of Warcraft(WoW). Они собрали данные о социальном графе игроков внутри игры и его изменениях за шесть месяцев. Авторы с помощью своего методы пытались предсказать то, что игрок в скором времени покинет гильдию (социальную группу внутри игры). В пользу необычного выбора набора данных приводится, что данных много, содержат в себе зловредные поведения, публичны и не ограничены правилами конфиденциальности. Авторы утверждают, что предложенный ими метод можно применять также и на реальных предприятиях.\\

В статье \cite{yuanInsiderThreatDetection2018b} используется следующий подход: сначала LSTM выучивает поведение пользователя по его действиям и извлекает временные признаки, затем извлеченные признаки подаются на вход CNN классификатору.\\

%%% Описание CNN %%%
\textbf{Сверточные нейронные сети CNN} - специальная разновидность архитектур нейронных сетей, в которой слои, выполняющие свертку, чередуются со слоями субдискретизации. На данный момент, CNN является одним из лучших алгоритмов по распознаванию и классификации изображений.\\

Поведения пользователя рассматривается как последовательность действий и действия одного пользователя соответствует одному "предложению", как в обычных NLP задачах. Все действия пользователя перед подачей на вход модели one-hot кодируются. После подачи каждого действия каждый скрытый слой LSTM выдает вектор, который выражает текущее состояние сети в пространстве малой размерности. Выходы последнего слоя собираются в одну матрицу, которая затем приводится к фиксированному размеру с помощью отбрасывания лишних векторов в случае длинных последовательностей действий и заполнения нулями в случае коротких последовательностей. Полученная матрица подается на вход CNN сети, которая в свою очередь предсказывает аномальность поведения. Авторы пишут, что их метод показал $AUC ROC=0.9449$ на отложенной выборке CERT.\\

В другой работе \cite{saaudiInsiderThreatsDetection2019} используется обратный подход. В ней CNN с одномерными сверточными слоями сначала пытается извлечь признаки, затем они подаются на вход LSTM для классификации. Значимое отличие от предыдущей работы заключается в том, что отображение поведения пользователей происходит с помощью представления каждого отдельного действия вектором малой размерностью. Значения этого вектора характеризуются соседними действиями, которые обычно встречаются вместе с ним. Авторы не указывают точно какой метод они использовали, но по описанию это очень похоже на популярный подход word2vec \cite{mikolovEfficientEstimationWord2013a}. Также авторы использовали технику SMOTE \cite{chawlaSMOTESyntheticMinority2002} для семплирования объектов малого класса и исправления сильного дисбаланса классов в наборе данных. SMOTE генерирует синтетические данные, которые похожи на $k$ ближайших соседей малого класса.\\

Обе работы \cite{saaudiInsiderThreatsDetection2019} и \cite{yuanInsiderThreatDetection2018b} ставят свою задачу как бинарную классификацию, в которой алгоритму необходимо определить аномальность поведения пользователя за некоторый промежуток времени (в обеих статьях рассматривают данные по дням)

В работе \cite{yuanAttentionBasedLSTMInsider2019} исследуется применение механизма \textbf{Attention} (внимание) для задачи обнаружения инсайдеров. Этот механизм позволяет сети обращать особое внимание для некоторых важных действий. Attention-слой в данной сети собирают выходы LSTM-слоя в один вектор, присваивая различный вес каждому выходу в зависимости от его важности. Как показали эксперименты в \cite{yuanAttentionBasedLSTMInsider2019}, добавление Attention увеличивает AUC ROC для LSTM и RNN сетей при использовании набора данных CERT.\\

Для поиска аномалий также возможно применение нейронных сетей из области распознавания изображений. Вдохновленные недавними успехами в применении нейросетей для анализа изображений для классификации вредоносных программ, \cite{gImageBasedFeatureRepresentation2019} применили этот подход для задачи обнаружении инсайдерской угрозы. В этой работе из набора данных CERT было вручную отобрано 20 признаков, и для каждого пользователя отдельно по этим признаком составлялись изображения 32 на 32 пикселей, которые подавались предобученной на ImageNet популярным нейросетевым моделям VGG16 и MobileNet. В результате было получено 99.32 точность и полнота на отложенной выборке.\\

Также, как показано в статье \cite{yuanAttentionBasedLSTMInsider2019}, техника attention в применении к поведенческой информации пользователя, способна значительно улучшить качество работы модели, позволяя модели давать разный вес элементам последовательности в зависимости от важности этого элемента. Это открывает потенциал для работы с семейством моделей BERT \cite{devlinBERTPretrainingDeep2019}, чей успех в NLP задачах приписывается слоям-трансформерам, которые, в свою очередь, используют attention. Поэтому с помощью модели BERT можно анализировать последовательность действий пользователя.\\

В \cite{leEvaluatingInsiderThreat2018} представлен подход представления данных для последующего анализа, который заключаются в использовании как \textit{последовательных} данных (последовательность действий конкретного пользователя за некоторый период времени), так и \textit{численных} данных. Численные данные в данной работе делятся на пользовательские и данные о действиях. Пользовательские данные в наборе данных CERT представлены информацией о роли пользователя в подразделении, его отделе и психометрике. Данные о действиях получаются подсчетом количества совершенных действий одной категории за рассматриваемый промежуток времени. Контентные данные набора данных CERT не были рассмотрены по силу синтетической природы набора данных.

Архитектуры рекуррентных сетей изначально предполагают работу только с последовательными данными. Чтобы совместить последовательные и численные данные можно использовать подход предложенный в \cite{karpathyDeepVisualSemanticAlignments2015}. В данной статье решалась задача автоматической аннотации изображений, которая состоит в выделением некоторых участков изображения с различными объектами и генерация текстового описания объеков в этих участках. Для генерации текста использовалась архитектура RNN, в которой начальное состояние скрытых слоев зависит от информационного вектора о соответствующем участке изображения. Таким образом, все состояния рекуррентной сети обусловлены содержанием изображения. Этот подход успешно решал поставленную задачу.
Нетрудно расширить этот подход для произвольного числового вектора $\overrightarrow{x}$, который также называется \textit{условным}. Мы можем преобразовать условный вектор так, чтобы он совпадал по размеру с вектором скрытого состояния рекуррентной сети $\overrightarrow{h}$. Для этого достаточно применить следующее простое преобразование:

$$\overrightarrow{h_0} = \mathbf{W}\overrightarrow{x} + \overrightarrow{b}$$
где $\mathbf{W}$ и $\overrightarrow{b}$ являются обучаемыми параметрами. Затем, полученным вектором можно инициализировать скрытое состояние рекуррентой сети. Процесс повторяется для каждой обрабатываемой рекуррентной сетью последовательностью.

В статье \cite{leAnalyzingDataGranularity2020b} на наборе данных сравниваются модели с различными рассматривамыми периодами для каждого пользователя: день, неделя и пользовательская сессия. Для данного периода собирались числовые данные о частоте событий и их статистические признаки, такие как среднее, медиана и стандартное отклонение. В результате исследования модели, которые были обучены на полных пользовательских сессиях дали лучший результат.

LSTM также используется в Unsupervised-режиме в работе \cite{paulLACLSTMAUTOENCODER}. В данной работе рассматривается обучение LSTM-автокодировщика. Также авторы в данной работе разбивают всех пользователей в наборе данных CERT по 8 непересекающимся сообществам. Авторы предлагают находить потенциальных инсайдеров по тому, насколько они выделяются внутри своего сообщества. Эксперименты показали, что таким способом можно успешно найти всех инсайдеров среди пяти наиболее аномальных пользователей из каждого сообщества. Эксперименты проводились на наборе данных CERT v6.2.

В работе \cite{tuorDeepLearningUnsupervised2017} используется похожий Unsupervised-подход с LSTM. Модель была обучена на задаче предсказания следующего действия в последовательности. Для определения аномальности используется отклонения действий пользователя от предсказанных моделью. Авторы называют главными преумеществами своего подхода интерпретируемость результатов модели и возможность онлайн-обучения.